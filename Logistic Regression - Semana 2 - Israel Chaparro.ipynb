{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Logistic Regression - Israel Chaparro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from http://nbviewer.jupyter.org/github/rasbt/pattern_classification/blob/master/machine_learning/scikit-learn/outofcore_modelpersistence.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The IMDb Movie Review Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train a simple logistic regression model to classify movie reviews from the 50k IMDb review dataset that has been collected by Maas et. al.\n",
    "\n",
    "> AL Maas, RE Daly, PT Pham, D Huang, AY Ng, and C Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Lin- guistics: Human Language Technologies, pages 142â€“150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics\n",
    "\n",
    "[Source: http://ai.stanford.edu/~amaas/data/sentiment/]\n",
    "\n",
    "The dataset consists of 50,000 movie reviews from the original \"train\" and \"test\" subdirectories. The class labels are binary (1=positive and 0=negative) and contain 25,000 positive and 25,000 negative movie reviews, respectively.\n",
    "For simplicity, I assembled the reviews in a single CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>OK, lets start with the best. the building. al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The British 'heritage film' industry is out of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I don't even know where to begin on this one. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I waited long to watch this movie. Also becaus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('shuffled_movie_data.csv') #too big for upload to github :(\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean         0.500000\n",
       "std          0.500005\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.500000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "## uncomment these lines if you have dowloaded the original file:\n",
    "#np.random.seed(0)\n",
    "#df = df.reindex(np.random.permutation(df.index))\n",
    "#df[['review', 'sentiment']].to_csv('shuffled_movie_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us define a simple `tokenizer` that splits the text into individual word tokens. Furthermore, we will use some simple regular expression to remove HTML markup and all non-letter characters but \"emoticons,\" convert the text to lower case, remove stopwords, and apply the Porter stemming algorithm to convert the words into their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "pronouns12=stop[:17]\n",
    "stop=stop[17:]\n",
    "#porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    #emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())# + ' '.join(emoticons).replace('-', '')\n",
    "    text = [w for w in text.split() if w not in stop]\n",
    "    #tokenized = [porter.stem(w) for w in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it at try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'algorithms', 'world', 'me']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('This :) is a <a> test of all algorithms in the world for me! :-)</br>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** WARNING ***\n",
    "The next code is for recalculate the features, there are commented and in the next cell we import directly the calculated features. You can recalculate the features changing the type of the next cell to \"CODE\".\n",
    "The features used are like https://web.stanford.edu/~jurafsky/slp3/5.pdf Part: 5.1.1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#import positive words\n",
    "with open('https://raw.githubusercontent.com/ichaparroc/IMDb-Movie-Review/master/positive-words.txt', 'rb') as f:\n",
    "    s = f.read().replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    positive = s.split('\\n')\n",
    "positive.pop()\n",
    "\n",
    "#import negative words\n",
    "with open('https://raw.githubusercontent.com/ichaparroc/IMDb-Movie-Review/master/negative-words.txt', 'rb') as f:\n",
    "    s = f.read().replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    negative = s.split('\\n')\n",
    "negative.pop()\n",
    "\n",
    "features=[]\n",
    "i=0\n",
    "for review in df[\"review\"]:\n",
    "\n",
    "    tokens=tokenizer(review)\n",
    "    \n",
    "    n_positive=0\n",
    "    for word_p in positive:\n",
    "        n_positive+=tokens.count(word_p)\n",
    "    \n",
    "    n_negative=0\n",
    "    for word_n in negative:\n",
    "        n_negative+=tokens.count(word_n)\n",
    "    \n",
    "    exist_no=tokens.count(\"no\")\n",
    "    \n",
    "    n_pronouns=0\n",
    "    pronouns12=[\"i\",\"me\",\"my\",\"mine\",\"we\",\"us\",\"our\",\"ours\",\"you\",\"your\",\"yours\"]\n",
    "    for pronoun in pronouns12:\n",
    "        n_pronouns+=tokens.count(pronoun)\n",
    "       \n",
    "    if review.find(\"!\")!=-1:\n",
    "        exclamation=1\n",
    "    else:\n",
    "        exclamation=0\n",
    "    \n",
    "    features+=[[n_positive,n_negative,exist_no,n_pronouns,exclamation,np.log(len(tokens))]]\n",
    "    i=i+1\n",
    "    print i\n",
    "    \n",
    "features=np.asarray(features)\n",
    "target=df.values[:,1]\n",
    "target = np.reshape(target,(target.shape[0],1))\n",
    "print target\n",
    "print features\n",
    "np.savetxt(\"features.csv\", features, delimiter=\",\")\n",
    "np.savetxt(\"target.csv\", target, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          8.         14.         ...  1.          0.\n",
      "   4.8598124 ]\n",
      " [ 1.         13.         10.         ... 15.          1.\n",
      "   4.8598124 ]\n",
      " [ 1.         14.         21.         ...  6.          1.\n",
      "   5.04985601]\n",
      " ...\n",
      " [ 1.          2.          4.         ...  4.          1.\n",
      "   4.2341065 ]\n",
      " [ 1.          4.          3.         ...  0.          0.\n",
      "   3.91202301]\n",
      " [ 1.          4.          1.         ...  4.          0.\n",
      "   3.25809654]]\n",
      "(50000, 7)\n",
      "(50000, 1)\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "## Impoting Features\n",
    "from numpy import genfromtxt\n",
    "features = genfromtxt('https://raw.githubusercontent.com/ichaparroc/IMDb-Movie-Review/master/features.csv', delimiter=',')\n",
    "target = genfromtxt('https://raw.githubusercontent.com/ichaparroc/IMDb-Movie-Review/master/target.csv', delimiter=',')\n",
    "target = np.reshape(target,(target.shape[0],1))\n",
    "features = np.column_stack((np.ones(features.shape[0]),features))\n",
    "print features\n",
    "print features.shape\n",
    "print target.shape\n",
    "print target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 7)\n",
      "(10000, 7)\n",
      "(40000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,target,test_size=0.2,random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49755, 0.5098)\n",
      "(0.49755, 0.5098)\n",
      "(0.49755, 0.5098)\n",
      "(0.541375, 0.5504)\n",
      "(0.657025, 0.6546)\n",
      "(0.680325, 0.6779)\n",
      "(0.686375, 0.6851)\n",
      "(0.689525, 0.6901)\n",
      "(0.692675, 0.6932)\n",
      "(0.695725, 0.6945)\n",
      "(0.69765, 0.6948)\n",
      "(0.699625, 0.6969)\n",
      "(0.7015, 0.6993)\n",
      "(0.703275, 0.7025)\n",
      "(0.70435, 0.703)\n",
      "(0.705425, 0.7033)\n",
      "(0.7063, 0.7044)\n",
      "(0.70695, 0.7053)\n",
      "(0.707525, 0.7058)\n",
      "(0.709025, 0.7058)\n",
      "(0.71025, 0.7073)\n",
      "(0.711425, 0.7089)\n",
      "(0.711975, 0.7096)\n",
      "(0.713025, 0.7108)\n",
      "(0.71395, 0.7117)\n",
      "(0.714475, 0.7124)\n",
      "(0.71515, 0.7123)\n",
      "(0.7159, 0.7124)\n",
      "(0.716425, 0.7132)\n",
      "(0.7171, 0.7138)\n",
      "(0.71785, 0.7147)\n",
      "(0.718575, 0.7148)\n",
      "(0.719725, 0.7157)\n",
      "(0.72005, 0.7163)\n",
      "(0.72045, 0.7168)\n",
      "(0.721, 0.7172)\n",
      "(0.7212, 0.7178)\n",
      "(0.721775, 0.7183)\n",
      "(0.7222, 0.7183)\n",
      "(0.722225, 0.7192)\n",
      "(0.722875, 0.7192)\n",
      "(0.723175, 0.7197)\n",
      "(0.723725, 0.7202)\n",
      "(0.72445, 0.7213)\n",
      "(0.724825, 0.7219)\n",
      "(0.725025, 0.7229)\n",
      "(0.72545, 0.7235)\n",
      "(0.7263, 0.7246)\n",
      "(0.726575, 0.7243)\n",
      "(0.72705, 0.725)\n",
      "(0.72735, 0.7253)\n",
      "(0.727425, 0.7252)\n",
      "(0.7273, 0.7255)\n",
      "(0.727175, 0.7262)\n",
      "(0.72775, 0.7264)\n",
      "(0.7281, 0.7261)\n",
      "(0.728075, 0.7261)\n",
      "(0.728325, 0.7263)\n",
      "(0.728525, 0.7263)\n",
      "(0.72855, 0.7273)\n",
      "(0.72865, 0.7271)\n",
      "(0.728825, 0.7276)\n",
      "(0.728725, 0.7277)\n",
      "(0.7289, 0.728)\n",
      "(0.729125, 0.7281)\n",
      "(0.72945, 0.728)\n",
      "(0.7293, 0.7282)\n",
      "(0.729425, 0.7287)\n",
      "(0.729475, 0.7292)\n",
      "(0.729425, 0.7289)\n",
      "(0.7293, 0.729)\n",
      "(0.72945, 0.729)\n",
      "(0.7297, 0.7295)\n",
      "(0.729875, 0.7295)\n",
      "(0.729825, 0.7291)\n",
      "(0.73, 0.7289)\n",
      "(0.72985, 0.7287)\n",
      "(0.729925, 0.7287)\n",
      "(0.730125, 0.7288)\n",
      "(0.730325, 0.7291)\n",
      "(0.7305, 0.7288)\n",
      "(0.7304, 0.7289)\n",
      "(0.730375, 0.7292)\n",
      "(0.73035, 0.7293)\n",
      "(0.730325, 0.7294)\n",
      "(0.7303, 0.7295)\n",
      "(0.7302, 0.7296)\n",
      "(0.73015, 0.7296)\n",
      "(0.7302, 0.7296)\n",
      "(0.73035, 0.7293)\n",
      "(0.7305, 0.7297)\n",
      "(0.730475, 0.7294)\n",
      "(0.730525, 0.7294)\n",
      "(0.73045, 0.7297)\n",
      "(0.730625, 0.7297)\n",
      "(0.73075, 0.7296)\n",
      "(0.7307, 0.7299)\n",
      "(0.73075, 0.7299)\n",
      "(0.730825, 0.7299)\n",
      "(0.7309, 0.7301)\n",
      "(0.730975, 0.7303)\n",
      "(0.730975, 0.7303)\n",
      "(0.731025, 0.7302)\n",
      "(0.731075, 0.7302)\n",
      "(0.731125, 0.7305)\n",
      "(0.73115, 0.7304)\n",
      "(0.731175, 0.7304)\n",
      "(0.73125, 0.7306)\n",
      "(0.731325, 0.7309)\n",
      "(0.73135, 0.731)\n",
      "(0.731325, 0.7311)\n",
      "(0.7314, 0.731)\n",
      "(0.73125, 0.731)\n",
      "(0.731175, 0.7309)\n",
      "(0.7311, 0.7312)\n",
      "(0.731225, 0.7309)\n",
      "(0.731075, 0.7308)\n",
      "(0.7312, 0.7309)\n",
      "(0.73115, 0.7307)\n",
      "(0.731125, 0.7311)\n",
      "(0.7312, 0.7312)\n",
      "(0.731275, 0.7311)\n",
      "(0.731375, 0.731)\n",
      "(0.731375, 0.7309)\n",
      "(0.73135, 0.731)\n",
      "(0.73135, 0.7309)\n",
      "(0.731275, 0.7309)\n",
      "(0.73125, 0.7308)\n",
      "(0.731225, 0.7309)\n",
      "(0.731275, 0.7307)\n",
      "(0.7313, 0.7307)\n",
      "(0.73125, 0.7307)\n",
      "(0.731225, 0.7307)\n",
      "(0.73115, 0.7307)\n",
      "(0.731125, 0.7308)\n",
      "(0.73125, 0.7309)\n",
      "(0.731275, 0.7308)\n",
      "(0.731225, 0.7308)\n",
      "(0.731225, 0.731)\n",
      "(0.731225, 0.7309)\n",
      "(0.73115, 0.731)\n",
      "(0.7311, 0.7309)\n",
      "(0.7311, 0.7308)\n",
      "(0.731075, 0.7308)\n",
      "(0.73105, 0.7307)\n",
      "(0.731075, 0.7305)\n",
      "(0.731175, 0.7307)\n",
      "(0.73115, 0.7308)\n",
      "(0.731125, 0.7308)\n",
      "(0.73115, 0.7307)\n",
      "(0.731175, 0.7308)\n",
      "(0.73115, 0.7307)\n",
      "(0.7312, 0.7308)\n",
      "(0.731175, 0.7306)\n",
      "(0.731175, 0.7306)\n",
      "(0.73115, 0.7305)\n",
      "(0.731125, 0.7304)\n",
      "(0.731075, 0.7304)\n",
      "(0.731075, 0.7304)\n",
      "(0.731125, 0.7304)\n",
      "(0.731175, 0.7304)\n",
      "(0.731175, 0.7305)\n",
      "(0.731175, 0.7305)\n",
      "(0.7312, 0.7305)\n",
      "(0.7312, 0.7305)\n",
      "(0.731275, 0.7305)\n",
      "(0.7313, 0.7305)\n",
      "(0.731275, 0.7305)\n",
      "(0.731275, 0.7305)\n",
      "(0.73125, 0.7305)\n",
      "(0.731175, 0.7305)\n",
      "(0.7312, 0.7305)\n",
      "(0.731225, 0.7305)\n",
      "(0.731225, 0.7305)\n",
      "(0.7312, 0.7305)\n",
      "(0.7312, 0.7305)\n",
      "(0.7312, 0.7305)\n",
      "(0.731175, 0.7305)\n",
      "(0.731175, 0.7305)\n",
      "(0.7311, 0.7305)\n",
      "(0.73115, 0.7305)\n",
      "(0.73115, 0.7308)\n",
      "(0.73115, 0.7307)\n",
      "(0.7311, 0.7306)\n",
      "(0.7311, 0.7306)\n",
      "(0.731125, 0.7305)\n",
      "(0.731125, 0.7305)\n",
      "(0.73115, 0.7305)\n",
      "(0.7311, 0.7305)\n",
      "(0.73105, 0.7306)\n",
      "(0.73105, 0.7306)\n",
      "(0.731075, 0.7307)\n",
      "(0.731025, 0.7307)\n",
      "(0.73105, 0.7307)\n",
      "(0.731125, 0.7306)\n",
      "(0.7311, 0.7306)\n",
      "(0.7311, 0.7306)\n",
      "(0.731175, 0.7306)\n",
      "(0.731175, 0.7307)\n",
      "(0.7311, 0.7308)\n",
      "(0.7311, 0.7308)\n",
      "(0.7311, 0.7308)\n",
      "(0.731075, 0.7308)\n",
      "(0.731025, 0.7308)\n",
      "(0.73105, 0.7308)\n",
      "(0.73105, 0.7308)\n",
      "(0.73105, 0.7308)\n",
      "(0.730975, 0.7308)\n",
      "(0.730975, 0.7308)\n",
      "(0.731, 0.7308)\n",
      "(0.731, 0.7308)\n",
      "(0.730975, 0.7309)\n",
      "(0.730975, 0.7309)\n",
      "(0.731, 0.731)\n",
      "(0.731, 0.731)\n",
      "(0.730975, 0.731)\n",
      "(0.73095, 0.731)\n",
      "(0.730975, 0.731)\n",
      "(0.730975, 0.7311)\n",
      "(0.73095, 0.731)\n",
      "(0.731, 0.731)\n",
      "(0.73095, 0.7309)\n",
      "(0.73095, 0.7309)\n",
      "(0.730925, 0.7309)\n",
      "(0.730925, 0.7309)\n",
      "(0.730925, 0.7309)\n",
      "(0.730925, 0.7309)\n",
      "(0.730925, 0.7309)\n",
      "(0.730825, 0.7312)\n",
      "(0.73085, 0.7312)\n",
      "(0.73085, 0.7313)\n",
      "(0.730875, 0.7313)\n",
      "(0.730875, 0.7314)\n",
      "(0.730875, 0.7315)\n",
      "(0.730925, 0.7315)\n",
      "(0.7309, 0.7314)\n",
      "(0.730925, 0.7314)\n",
      "(0.730925, 0.7314)\n",
      "(0.730925, 0.7314)\n",
      "(0.7309, 0.7314)\n",
      "(0.730925, 0.7314)\n",
      "(0.730925, 0.7314)\n",
      "(0.73095, 0.7315)\n",
      "(0.730975, 0.7315)\n",
      "(0.73095, 0.7315)\n",
      "(0.730975, 0.7315)\n",
      "(0.73095, 0.7315)\n",
      "(0.730925, 0.7315)\n",
      "(0.730925, 0.7315)\n",
      "(0.730875, 0.7315)\n",
      "(0.73095, 0.7315)\n",
      "(0.730925, 0.7315)\n",
      "(0.730925, 0.7315)\n",
      "(0.73095, 0.7315)\n",
      "(0.730975, 0.7313)\n",
      "(0.731, 0.7313)\n",
      "(0.73105, 0.7313)\n",
      "(0.731075, 0.7313)\n",
      "(0.7311, 0.7313)\n",
      "(0.73105, 0.7313)\n",
      "(0.73105, 0.7313)\n",
      "(0.731075, 0.7313)\n",
      "(0.731075, 0.7313)\n",
      "(0.731075, 0.7313)\n",
      "(0.731125, 0.7313)\n",
      "(0.731125, 0.7315)\n",
      "(0.73115, 0.7315)\n",
      "(0.73115, 0.7316)\n",
      "(0.73115, 0.7316)\n",
      "(0.7312, 0.7316)\n",
      "(0.731225, 0.7316)\n",
      "(0.731225, 0.7316)\n",
      "(0.7312, 0.7316)\n",
      "(0.7312, 0.7317)\n",
      "(0.731225, 0.7317)\n",
      "(0.73125, 0.7317)\n",
      "(0.73125, 0.7317)\n",
      "(0.731275, 0.7316)\n",
      "(0.731275, 0.7316)\n",
      "(0.731325, 0.7317)\n",
      "(0.731275, 0.7317)\n",
      "(0.731325, 0.7319)\n",
      "(0.7313, 0.7319)\n",
      "(0.7313, 0.7319)\n",
      "(0.731325, 0.7318)\n",
      "(0.731325, 0.7318)\n",
      "(0.731325, 0.7319)\n",
      "(0.73135, 0.732)\n",
      "(0.731375, 0.7321)\n",
      "(0.731375, 0.7321)\n",
      "(0.731475, 0.7322)\n",
      "(0.731475, 0.7322)\n",
      "(0.73145, 0.7322)\n",
      "(0.73145, 0.7323)\n",
      "(0.731475, 0.7323)\n",
      "(0.731475, 0.7323)\n",
      "(0.731475, 0.7323)\n",
      "(0.73145, 0.7324)\n",
      "(0.731425, 0.7324)\n",
      "(0.7314, 0.7324)\n",
      "(0.731375, 0.7324)\n",
      "(0.731375, 0.7324)\n",
      "(0.731425, 0.7323)\n",
      "(0.73145, 0.7324)\n",
      "(0.731425, 0.7323)\n",
      "(0.731425, 0.7323)\n",
      "(0.73145, 0.7323)\n",
      "(0.73145, 0.7321)\n",
      "(0.731425, 0.7321)\n",
      "(0.7314, 0.7321)\n",
      "(0.7314, 0.7321)\n",
      "(0.7314, 0.732)\n",
      "(0.7314, 0.732)\n",
      "(0.7314, 0.732)\n",
      "(0.7314, 0.732)\n",
      "(0.731475, 0.7321)\n",
      "(0.731475, 0.7321)\n",
      "(0.731475, 0.7321)\n",
      "(0.731475, 0.7322)\n",
      "(0.73145, 0.7322)\n",
      "(0.73145, 0.7322)\n",
      "(0.73145, 0.7322)\n",
      "(0.7314, 0.7322)\n",
      "(0.731425, 0.7322)\n",
      "(0.731475, 0.7322)\n",
      "(0.731475, 0.7321)\n",
      "(0.731475, 0.7321)\n",
      "(0.731425, 0.7321)\n",
      "(0.7314, 0.7321)\n",
      "(0.731325, 0.732)\n",
      "(0.731375, 0.732)\n",
      "(0.731375, 0.732)\n",
      "(0.73135, 0.7321)\n",
      "(0.731325, 0.7322)\n",
      "(0.731325, 0.7322)\n",
      "(0.7313, 0.7321)\n",
      "(0.731375, 0.7321)\n",
      "(0.731375, 0.7321)\n",
      "(0.7314, 0.7321)\n",
      "(0.7314, 0.7321)\n",
      "(0.731375, 0.7321)\n",
      "(0.731425, 0.7321)\n",
      "(0.7314, 0.7322)\n",
      "(0.7314, 0.7322)\n",
      "(0.7314, 0.7321)\n",
      "(0.731425, 0.7321)\n",
      "(0.731425, 0.732)\n",
      "(0.7314, 0.732)\n",
      "(0.731375, 0.732)\n",
      "(0.7314, 0.732)\n",
      "(0.731375, 0.7319)\n",
      "(0.7314, 0.7319)\n",
      "(0.7314, 0.7319)\n",
      "(0.7314, 0.7319)\n",
      "(0.7314, 0.7319)\n",
      "(0.7314, 0.7319)\n",
      "(0.731375, 0.7318)\n",
      "(0.731375, 0.7318)\n",
      "(0.731425, 0.7318)\n",
      "(0.731425, 0.7318)\n",
      "(0.731425, 0.7318)\n",
      "(0.731425, 0.7318)\n",
      "(0.73135, 0.7318)\n",
      "(0.731325, 0.7318)\n",
      "(0.731325, 0.7318)\n",
      "(0.7313, 0.7318)\n",
      "(0.731275, 0.7318)\n",
      "(0.731275, 0.7318)\n",
      "(0.7313, 0.7318)\n",
      "(0.731275, 0.7317)\n",
      "(0.731325, 0.7317)\n",
      "(0.731325, 0.7317)\n",
      "(0.731375, 0.7318)\n",
      "(0.73135, 0.7318)\n",
      "(0.73135, 0.7318)\n",
      "(0.7314, 0.7318)\n",
      "(0.7314, 0.7318)\n",
      "(0.7314, 0.7318)\n",
      "(0.7314, 0.7318)\n",
      "(0.731375, 0.7318)\n",
      "(0.731325, 0.7319)\n",
      "(0.731325, 0.7319)\n",
      "(0.73135, 0.7319)\n",
      "(0.73135, 0.7319)\n",
      "(0.73135, 0.7319)\n",
      "(0.731375, 0.7319)\n",
      "(0.731375, 0.7319)\n",
      "(0.73135, 0.7319)\n",
      "(0.73135, 0.7319)\n",
      "(0.731375, 0.7319)\n",
      "(0.7314, 0.7319)\n",
      "(0.7314, 0.7319)\n",
      "(0.731425, 0.732)\n",
      "(0.7314, 0.732)\n",
      "(0.7315, 0.732)\n",
      "(0.73155, 0.732)\n",
      "(0.73155, 0.732)\n",
      "(0.73155, 0.732)\n",
      "(0.731525, 0.732)\n",
      "(0.731575, 0.7321)\n",
      "(0.7316, 0.7321)\n",
      "(0.731575, 0.7321)\n",
      "(0.731575, 0.7322)\n",
      "(0.7316, 0.7321)\n",
      "(0.7316, 0.7321)\n",
      "(0.731625, 0.7322)\n",
      "(0.731625, 0.7322)\n",
      "(0.731625, 0.7322)\n",
      "(0.731625, 0.7322)\n",
      "(0.731625, 0.7322)\n",
      "(0.731625, 0.7321)\n",
      "(0.7316, 0.7321)\n",
      "(0.731575, 0.7321)\n",
      "(0.731525, 0.7321)\n",
      "(0.73155, 0.7322)\n",
      "(0.731575, 0.7322)\n",
      "(0.7316, 0.7322)\n",
      "(0.7316, 0.7322)\n",
      "(0.7316, 0.7322)\n",
      "(0.7316, 0.7323)\n",
      "(0.73165, 0.7323)\n",
      "(0.731675, 0.7323)\n",
      "(0.7317, 0.7323)\n",
      "(0.731675, 0.7323)\n",
      "(0.731675, 0.7323)\n",
      "(0.73165, 0.7323)\n",
      "(0.731625, 0.7323)\n",
      "(0.731625, 0.7323)\n",
      "(0.731625, 0.7323)\n",
      "(0.731625, 0.7323)\n",
      "(0.7316, 0.7323)\n",
      "(0.731625, 0.7323)\n",
      "(0.73165, 0.7323)\n",
      "(0.731625, 0.7323)\n",
      "(0.731625, 0.7323)\n",
      "(0.73165, 0.7323)\n",
      "(0.73165, 0.7323)\n",
      "(0.73165, 0.7323)\n",
      "(0.731675, 0.7323)\n",
      "(0.731675, 0.7323)\n",
      "(0.731725, 0.7323)\n",
      "(0.73175, 0.7324)\n",
      "(0.73175, 0.7324)\n",
      "(0.73175, 0.7324)\n",
      "(0.731775, 0.7324)\n",
      "(0.73175, 0.7324)\n",
      "(0.73175, 0.7324)\n",
      "(0.731675, 0.7324)\n",
      "(0.731675, 0.7325)\n",
      "(0.7317, 0.7327)\n",
      "(0.731725, 0.7327)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.731725, 0.7327)\n",
      "(0.7317, 0.7327)\n",
      "(0.731725, 0.7326)\n",
      "(0.731725, 0.7325)\n",
      "(0.73175, 0.7326)\n",
      "(0.731775, 0.7327)\n",
      "(0.731775, 0.7328)\n",
      "(0.731775, 0.7328)\n",
      "(0.731775, 0.7328)\n",
      "(0.731775, 0.7328)\n",
      "(0.731775, 0.7328)\n",
      "(0.731775, 0.7328)\n",
      "(0.731875, 0.7328)\n",
      "(0.731875, 0.7328)\n",
      "(0.731925, 0.7328)\n",
      "(0.731925, 0.7328)\n",
      "(0.731925, 0.7328)\n",
      "(0.7319, 0.7327)\n",
      "(0.7319, 0.7326)\n",
      "(0.7319, 0.7327)\n",
      "(0.7319, 0.7327)\n",
      "(0.73195, 0.7327)\n",
      "(0.73195, 0.7326)\n",
      "(0.73195, 0.7326)\n",
      "(0.73195, 0.7326)\n",
      "(0.73195, 0.7326)\n",
      "(0.731925, 0.7327)\n",
      "(0.73195, 0.7327)\n",
      "(0.731975, 0.7327)\n",
      "(0.731975, 0.7327)\n",
      "(0.731975, 0.7327)\n",
      "(0.731975, 0.7327)\n",
      "(0.731975, 0.7327)\n",
      "(0.731975, 0.7327)\n",
      "(0.7319, 0.7327)\n",
      "(0.7319, 0.7327)\n",
      "(0.731925, 0.7327)\n",
      "(0.7319, 0.7327)\n",
      "(0.7319, 0.7326)\n",
      "(0.7319, 0.7326)\n",
      "(0.7319, 0.7326)\n",
      "(0.7319, 0.7326)\n",
      "(0.7319, 0.7325)\n",
      "(0.7319, 0.7325)\n",
      "(0.7319, 0.7325)\n",
      "(0.731875, 0.7325)\n",
      "(0.7319, 0.7325)\n",
      "(0.7319, 0.7326)\n",
      "(0.7319, 0.7326)\n",
      "(0.7319, 0.7326)\n",
      "(0.7319, 0.7325)\n",
      "(0.7319, 0.7325)\n",
      "(0.731925, 0.7325)\n",
      "(0.731925, 0.7327)\n",
      "(0.731925, 0.7327)\n",
      "(0.731925, 0.7327)\n",
      "(0.731875, 0.7328)\n",
      "(0.7319, 0.7328)\n",
      "(0.731925, 0.7328)\n",
      "(0.73195, 0.7329)\n",
      "(0.731925, 0.7329)\n",
      "(0.73195, 0.7329)\n",
      "(0.73195, 0.7328)\n",
      "(0.73195, 0.7328)\n",
      "(0.731975, 0.7328)\n",
      "(0.732, 0.7328)\n",
      "(0.732025, 0.7326)\n",
      "(0.732025, 0.7326)\n",
      "(0.73205, 0.7327)\n",
      "(0.732025, 0.7327)\n",
      "(0.732025, 0.7327)\n",
      "(0.732, 0.7328)\n",
      "(0.732025, 0.7327)\n",
      "(0.732025, 0.7327)\n",
      "(0.732025, 0.7327)\n",
      "(0.732025, 0.7327)\n",
      "(0.732025, 0.7327)\n",
      "(0.73205, 0.7327)\n",
      "(0.73205, 0.7327)\n",
      "(0.732075, 0.7327)\n",
      "(0.732075, 0.7327)\n",
      "(0.73205, 0.7326)\n",
      "(0.7321, 0.7326)\n",
      "(0.7321, 0.7327)\n",
      "(0.7321, 0.7326)\n",
      "(0.7321, 0.7325)\n",
      "(0.7321, 0.7325)\n",
      "(0.732075, 0.7325)\n",
      "(0.732075, 0.7325)\n",
      "(0.732075, 0.7325)\n",
      "(0.732075, 0.7326)\n",
      "(0.7321, 0.7325)\n",
      "(0.732125, 0.7325)\n",
      "(0.7321, 0.7325)\n",
      "(0.73205, 0.7325)\n",
      "(0.732, 0.7325)\n",
      "(0.731975, 0.7325)\n",
      "(0.73195, 0.7325)\n",
      "(0.731925, 0.7324)\n",
      "(0.731925, 0.7324)\n",
      "(0.731925, 0.7324)\n",
      "(0.7319, 0.7323)\n",
      "(0.7319, 0.7323)\n",
      "(0.731875, 0.7323)\n",
      "(0.731875, 0.7323)\n",
      "(0.731875, 0.7324)\n",
      "(0.7319, 0.7324)\n",
      "(0.7319, 0.7323)\n",
      "(0.73195, 0.7323)\n",
      "(0.73195, 0.7323)\n",
      "(0.731925, 0.7323)\n",
      "(0.731925, 0.7323)\n",
      "(0.731925, 0.7322)\n",
      "(0.73195, 0.7322)\n",
      "(0.73195, 0.7322)\n",
      "(0.731925, 0.7322)\n",
      "(0.73195, 0.7321)\n",
      "(0.732, 0.7321)\n",
      "(0.731975, 0.7321)\n",
      "(0.732, 0.7321)\n",
      "(0.732025, 0.7321)\n",
      "(0.732025, 0.732)\n"
     ]
    }
   ],
   "source": [
    "train_accuracy=[]\n",
    "test_accuracy=[]\n",
    "alpha=0.0000000001\n",
    "theta=np.random.rand(1,X_train.shape[1])#/X_train.shape[0]\n",
    "max_epoch=50000000\n",
    "for epoch in range(max_epoch):\n",
    "    hx_train=(1.0/(1.0+np.exp(-np.matmul(theta,np.transpose(X_train)))))\n",
    "    error=np.transpose(y_train)-hx_train\n",
    "    np.around(y_train)\n",
    "    dtheta=np.matmul(error,X_train)\n",
    "    theta+=alpha*dtheta#/X_train.shape[0]\n",
    "    if epoch%10000==0:\n",
    "        hx_test=(1.0/(1.0+np.exp(-np.matmul(theta,np.transpose(X_test)))))\n",
    "        train_accuracy.append((X_train.shape[0]-np.sum(np.absolute(np.around(np.transpose(y_train)-hx_train))))/X_train.shape[0])\n",
    "        test_accuracy.append((X_test.shape[0]-np.sum(np.absolute(np.around(np.transpose(y_test)-hx_test))))/X_test.shape[0])\n",
    "        print ((X_train.shape[0]-np.sum(np.absolute(np.around(np.transpose(y_train)-hx_train))))/X_train.shape[0],(X_test.shape[0]-np.sum(np.absolute(np.around(np.transpose(y_test)-hx_test))))/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_accuracy = genfromtxt('https://raw.githubusercontent.com/ichaparroc/IMDb-Movie-Review/master/temp_train.txt', delimiter=',')\n",
    "#test_accuracy = genfromtxt('https://raw.githubusercontent.com/ichaparroc/IMDb-Movie-Review/master/temp_test.txt', delimiter=',')\n",
    "import matplotlib.pyplot as plt\n",
    "temp_series=np.linspace(1,5500000,num=550)\n",
    "plt.plot(temp_series, train_accuracy, color='red')\n",
    "plt.plot(temp_series, test_accuracy, color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Train vs Test')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
